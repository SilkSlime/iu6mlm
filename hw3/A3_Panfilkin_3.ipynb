{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДОМАШНЕЕ ЗАДАНИЕ 3. Классификация текстовых документов\n",
    "## Цель работы\n",
    "\n",
    "Приобрести опыт решения практических задач по машинному обучению, таких как анализ и визуализация исходных данных, обучение, выбор и оценка качества моделей предсказания, посредством языка программирования Python."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import (\n",
    "    TfidfVectorizer,\n",
    "    CountVectorizer,\n",
    "    HashingVectorizer,\n",
    "    TfidfTransformer\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "\n",
    "# Выключаем ворнинги, чтобы не засорять вывод при обучении логистической регрессии\n",
    "# с неоптиимальными параметрами (при GridSearchCV такое будет)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Фиксируем RANDOM_STATE как константу для воспроизводимости результатов\n",
    "RANDOM_STATE = 123"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вариант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surname = \"Панфилкин\" # Ваша фамилия\n",
    "\n",
    "alp = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя'\n",
    "w = [4, 42, 21, 21, 34,  1, 44, 26, 18, 43, 38, 26, 18, 43,  3, 49, 45,\n",
    "        7, 42, 25,  4,  9, 36, 33, 31, 29,  5, 31,  4, 19, 24, 27, 33]\n",
    "d = dict(zip(alp, w))\n",
    "variant =  sum([d[el] for el in surname.lower()]) % 3 + 1\n",
    "print(\"Ваш вариант - \", variant)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1. Оценка качества классификации текстовых данных (2 балла)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных из файла data/reviews.tsv (первый столбец - метки классов, второй - тексты)\n",
    "data = pd.read_csv('data/reviews.tsv', sep='\\t', names=['target', 'text'])\n",
    "# Вытащим X и y из датафрейма\n",
    "X, y = data['text'], data['target']\n",
    "# Выведем количество наблюдений в каждом классе\n",
    "for target in y.unique():\n",
    "    print(f'Класс {target}: {len(y[y == target])} наблюдений')\n",
    "# Отобразим датафрейм с данными\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разделение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим данные на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    train_size=0.8,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "# Также определим KFold для дальнейшей кросс-валидации (везде будем использовать данный объект)\n",
    "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Определение функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(pipeline, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Функция для расчета метрик в виде словоря\n",
    "    \"\"\"\n",
    "    # Раскроем пайплайн и отдельно обучим векторайзер, чтобы время обучения векторайзера\n",
    "    # не учитывалось в метриках\n",
    "    vectorizer = pipeline['vectorizer']\n",
    "    classifier = pipeline['classifier']\n",
    "\n",
    "    # Векторизуем\n",
    "    X_train_ = vectorizer.fit_transform(X_train)\n",
    "    X_test_ = vectorizer.transform(X_test)\n",
    "\n",
    "    # Обучаем\n",
    "    start = time.time()\n",
    "    classifier.fit(X_train_, y_train)\n",
    "    fit_time = time.time() - start\n",
    "\n",
    "    # Предсказываем\n",
    "    start = time.time()\n",
    "    y_pred = classifier.predict(X_test_)\n",
    "    predict_time = time.time() - start\n",
    "\n",
    "    # Возвращаем все метрики \n",
    "    return {\n",
    "        'fit_time': fit_time,\n",
    "        'score_time': predict_time,\n",
    "        'test_balanced_accuracy': balanced_accuracy_score(y_test, y_pred),\n",
    "        'test_recall': recall_score(y_test, y_pred),\n",
    "        'test_precision': precision_score(y_test, y_pred),\n",
    "        'test_f1': f1_score(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "def cross_validate(pipeline, X, y, kf):\n",
    "    \"\"\"\n",
    "    Функция для расчета метрик в виде словоря для кросс валидации\n",
    "    \"\"\"\n",
    "    # Тут будем хранить результаты метрик по фолдам\n",
    "    metrics_list = []\n",
    "    for train_idx, test_idx in kf.split(X, y):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        metrics_list.append(get_metrics(pipeline, X_train, y_train, X_test, y_test))\n",
    "    # Через pandas усредним и приведем в одинаковый с get_metrics() вид\n",
    "    return pd.DataFrame(metrics_list).mean().to_dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Определение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для моделей определим векторайзер TF-IDF\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 1), lowercase=True)\n",
    "# Для модели Бернулли используем бинарный векторайзер\n",
    "vectorizer_binary = CountVectorizer(binary=True, ngram_range=(1, 1), lowercase=True)\n",
    "\n",
    "# Определим пайплайны\n",
    "pipelines = {\n",
    "    \"К-ближайших соседей\": Pipeline([\n",
    "        ('vectorizer', vectorizer),\n",
    "        ('classifier', KNeighborsClassifier(n_neighbors=5))\n",
    "    ]),\n",
    "    \"Логистическая регрессия\": Pipeline([\n",
    "        ('vectorizer', vectorizer),\n",
    "        ('classifier', LogisticRegression(\n",
    "            penalty='l2',\n",
    "            fit_intercept=True,\n",
    "            max_iter=100,\n",
    "            C=1,\n",
    "            solver='lbfgs',\n",
    "            random_state=RANDOM_STATE\n",
    "        ))\n",
    "    ]),\n",
    "    \"Наивный Байес: модель Бернулли\": Pipeline([\n",
    "        ('vectorizer', vectorizer_binary),\n",
    "        ('classifier', BernoulliNB(alpha=1))\n",
    "    ]),\n",
    "    \"Наивный Байес: полиномиальная модель\": Pipeline([\n",
    "        ('vectorizer', vectorizer),\n",
    "        ('classifier', MultinomialNB(alpha=1))\n",
    "    ])\n",
    "}\n",
    "# Для единства храним значения параметров (которые в последствии будем менять)\n",
    "param_names = [\"classifier__n_neighbors\", \"classifier__C\", \"classifier__alpha\", \"classifier__alpha\"]\n",
    "# И их значеня (можно было бы вытащить по имени, но так просто проще сейчас сделать)\n",
    "param_values = [5, 1, 1, 1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оценка моделей по отложенной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = {}\n",
    "for i, (method_name, pipeline) in enumerate(pipelines.items()):\n",
    "    param_name = param_names[i]\n",
    "    param_value = param_values[i]\n",
    "    label = f\"{method_name} ({param_name}={param_value})\"\n",
    "\n",
    "    metrics_dict[label] = get_metrics(pipeline, X_train, y_train, X_test, y_test)\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_dict).T\n",
    "metrics_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2. Оценка качества классификации текстовых данных посредством кросс-валидации (2 балла)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оценка моделей по кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = {}\n",
    "for i, (method_name, pipeline) in enumerate(pipelines.items()):\n",
    "    param_name = param_names[i]\n",
    "    param_value = param_values[i]\n",
    "    label = f\"{method_name} ({param_name}={param_value})\"\n",
    "    \n",
    "    metrics_dict[label] = cross_validate(pipeline, X, y, skf)\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_dict).T\n",
    "metrics_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3. Выбор модели (4 баллов)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Определение функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_scores(\n",
    "        pipelines, # Словарь с пайплайнами {название метода: пайплайн}\n",
    "        param_names, # Список с названиями параметров (размер как pipelines)\n",
    "        param_values_list # Список со списками значений параметров (размер как pipelines)\n",
    "    ):\n",
    "    '''\n",
    "    Функция для расчета метрик поиска по сетке в виде словоря используя кросс валидацию.\n",
    "    '''\n",
    "    # Словарь для хранения результатов\n",
    "    validation_scores = {}\n",
    "    # Для каждого метода\n",
    "    for i, (method_name, pipeline) in enumerate(pipelines.items()):\n",
    "        print(f\"Поиск лучшего значения гиперпараметра для модели '{method_name}'...\")\n",
    "        # Определяем параметры для поиска по сетке\n",
    "        gs = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid={f\"{param_names[i]}\": param_values_list[i]},\n",
    "            scoring='balanced_accuracy',\n",
    "            cv=skf,\n",
    "            refit=False, # Не обучаем модель на всех данных в конце (Экономим время)\n",
    "            return_train_score=True, # Возвращаем значения метрики на обучающей выборке\n",
    "        )\n",
    "        # Обучаем модель\n",
    "        gs.fit(X_train, y_train)\n",
    "        # Вытаскиваем нужные нам метрики и сохраняем в словарь\n",
    "        validation_scores[method_name] = {\n",
    "            'train_score': gs.cv_results_['mean_train_score'],\n",
    "            'test_score': gs.cv_results_['mean_test_score'],\n",
    "            'fit_time': gs.cv_results_['mean_fit_time'],\n",
    "            'score_time': gs.cv_results_['mean_score_time'],\n",
    "            'best_param_index': gs.best_index_\n",
    "        }\n",
    "    return validation_scores\n",
    "\n",
    "def plot_validation_scores(\n",
    "        validation_scores, # Словарь с метриками из get_validation_scores()\n",
    "        score_keys, # Список с ключами метрик для отрисовки\n",
    "        score_labels, # Список с подписями метрик для отрисовки\n",
    "        highlight_key, # Ключ метрики для подсветки лучшего значения\n",
    "        param_names, # Список с названиями параметров (размер как pipelines)\n",
    "        param_values_list, # Список со списками значений параметров (размер как pipelines)\n",
    "        xscales, # Список с типами шкал для оси X (линейная или логарифмическая)\n",
    "        title # Значение ngram_range для отрисовки в заголовке\n",
    "    ):\n",
    "    '''\n",
    "    Функция для визуализации результатов поиска по сетке.\n",
    "    '''\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    axes = axes.flatten()\n",
    "    for i, (ax, method_name) in enumerate(zip(axes, validation_scores)):\n",
    "        scores = validation_scores[method_name]\n",
    "        for score_key, score_label in zip(score_keys, score_labels):\n",
    "            ax.plot(param_values_list[i], scores[score_key], label=score_label, marker='o')\n",
    "\n",
    "        if highlight_key is not None:\n",
    "            # Определение лучшего значения гиперпараметра\n",
    "            best_param_index = validation_scores[method_name]['best_param_index']\n",
    "            best_param = param_values_list[i][best_param_index]\n",
    "            best_accuracy = validation_scores[method_name]['test_score'][best_param_index]\n",
    "            # Отметим точку с лучшим значением на графике\n",
    "            ax.scatter(best_param, best_accuracy, marker='o', color='black', zorder=3)\n",
    "            # Добавим подпись\n",
    "            ax.annotate(\n",
    "                f\"Top Result:\\n({best_param:.2f}, {best_accuracy:.2f})\",\n",
    "                xy=(best_param, best_accuracy),\n",
    "                xytext=(best_param, best_accuracy - 0.02),\n",
    "                horizontalalignment='center',\n",
    "                verticalalignment='top'\n",
    "            )\n",
    "\n",
    "        ax.set_title(method_name)\n",
    "        ax.set_xlabel(param_names[i])\n",
    "        ax.set_ylabel('Сбалансированная точность')\n",
    "        ax.set_xscale(xscales[i])\n",
    "        ax.legend()\n",
    "\n",
    "    # Фиксим пересечение подписей\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def set_best_params(pipelines, param_names, param_values_list, validation_scores):\n",
    "    for i, (method_name, pipeline) in enumerate(pipelines.items()):\n",
    "        best_param_index = validation_scores[method_name]['best_param_index']\n",
    "        best_param = param_values_list[i][best_param_index]\n",
    "        pipeline.set_params(**{f'{param_names[i]}': best_param})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определим диапазоны значений гиперпараметров\n",
    "param_values_list = [\n",
    "    np.arange(1, 150, 20),\n",
    "    np.logspace(-2, 10, 8, base=10),\n",
    "    np.logspace(-4, 1, 8, base=10),\n",
    "    np.logspace(-4, 1, 8, base=10)\n",
    "]\n",
    "\n",
    "# Список всех метрик лучгих моделей при каждом значении n-грамм\n",
    "metrics_list = []\n",
    "# Список оценок качества моделей при каждом значении n-грамм\n",
    "validation_scores = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оценка влияния гиперпараметров на точность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = (1, 1)\n",
    "vectorizer.set_params(ngram_range=ngram)\n",
    "vectorizer_binary.set_params(ngram_range=ngram)\n",
    "validation_scores[ngram] = get_validation_scores(pipelines, param_names, param_values_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### График гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_validation_scores(\n",
    "    validation_scores=validation_scores[ngram],\n",
    "    score_keys=['train_score', 'test_score'],\n",
    "    score_labels=['Train', 'Test'],\n",
    "    highlight_key='test_score',\n",
    "    param_names=param_names,\n",
    "    param_values_list=param_values_list,\n",
    "    xscales=['linear', 'log', 'log', 'log'],\n",
    "    title=f'Зависимость сбалансированной точности от гиперпараметров моделей [ngram={ngram}]'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_best_params(pipelines, param_names, param_values_list, validation_scores[ngram])\n",
    "for i, (method_name, pipeline) in enumerate(pipelines.items()):\n",
    "    param_name = param_names[i]\n",
    "    best_param_index = validation_scores[ngram][method_name]['best_param_index']\n",
    "    best_param = param_values_list[i][best_param_index]\n",
    "    metrics = cross_validate(pipeline, X, y, skf)\n",
    "    metrics = {\n",
    "        'method': method_name,\n",
    "        'ngram': str(ngram),\n",
    "        'param': f\"{param_name}={round(best_param, 2)}\",\n",
    "        **metrics\n",
    "    }\n",
    "    metrics_list.append(metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ngram=(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = (2, 2)\n",
    "vectorizer.set_params(ngram_range=ngram)\n",
    "vectorizer_binary.set_params(ngram_range=ngram)\n",
    "validation_scores[ngram] = get_validation_scores(pipelines, param_names, param_values_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_validation_scores(\n",
    "    validation_scores=validation_scores[ngram],\n",
    "    score_keys=['train_score', 'test_score'],\n",
    "    score_labels=['Train', 'Test'],\n",
    "    highlight_key='test_score',\n",
    "    param_names=param_names,\n",
    "    param_values_list=param_values_list,\n",
    "    xscales=['linear', 'log', 'log', 'log'],\n",
    "    title=f'Зависимость сбалансированной точности от гиперпараметров моделей [ngram={ngram}]'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_best_params(pipelines, param_names, param_values_list, validation_scores[ngram])\n",
    "for i, (method_name, pipeline) in enumerate(pipelines.items()):\n",
    "    param_name = param_names[i]\n",
    "    best_param_index = validation_scores[ngram][method_name]['best_param_index']\n",
    "    best_param = param_values_list[i][best_param_index]\n",
    "    metrics = cross_validate(pipeline, X, y, skf)\n",
    "    metrics = {\n",
    "        'method': method_name,\n",
    "        'ngram': str(ngram),\n",
    "        'param': f\"{param_name}={round(best_param, 2)}\",\n",
    "        **metrics\n",
    "    }\n",
    "    metrics_list.append(metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ngram=(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = (1, 2)\n",
    "vectorizer.set_params(ngram_range=ngram)\n",
    "vectorizer_binary.set_params(ngram_range=ngram)\n",
    "validation_scores[ngram] = get_validation_scores(pipelines, param_names, param_values_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_validation_scores(\n",
    "    validation_scores=validation_scores[ngram],\n",
    "    score_keys=['train_score', 'test_score'],\n",
    "    score_labels=['Train', 'Test'],\n",
    "    highlight_key='test_score',\n",
    "    param_names=param_names,\n",
    "    param_values_list=param_values_list,\n",
    "    xscales=['linear', 'log', 'log', 'log'],\n",
    "    title=f'Зависимость сбалансированной точности от гиперпараметров моделей [ngram={ngram}]'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_best_params(pipelines, param_names, param_values_list, validation_scores[ngram])\n",
    "for i, (method_name, pipeline) in enumerate(pipelines.items()):\n",
    "    param_name = param_names[i]\n",
    "    best_param_index = validation_scores[ngram][method_name]['best_param_index']\n",
    "    best_param = param_values_list[i][best_param_index]\n",
    "    metrics = cross_validate(pipeline, X, y, skf)\n",
    "    metrics = {\n",
    "        'method': method_name,\n",
    "        'ngram': str(ngram),\n",
    "        'param': f\"{param_name}={round(best_param, 2)}\",\n",
    "        **metrics\n",
    "    }\n",
    "    metrics_list.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним метрики в датафрейм и отобразим как таблицу\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "metrics_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4. Оценка влияния количества признаков FeatureHasher на качество классификации (2 баллов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashing_vectorizer = HashingVectorizer(norm=None, alternate_sign=False)\n",
    "tfidf_transformer = TfidfTransformer(norm=None)\n",
    "\n",
    "pipelines_hashing = {\n",
    "    'К-ближайших соседей': Pipeline([\n",
    "        ('vectorizer', hashing_vectorizer),\n",
    "        ('transformer', tfidf_transformer),\n",
    "        ('classifier', KNeighborsClassifier(n_neighbors=5))\n",
    "    ]),\n",
    "    'Логистическая регрессия': Pipeline([\n",
    "        ('vectorizer', hashing_vectorizer),\n",
    "        ('transformer', tfidf_transformer),\n",
    "        ('classifier', LogisticRegression(\n",
    "            penalty='l2',\n",
    "            fit_intercept=True,\n",
    "            max_iter=100,\n",
    "            C=1,\n",
    "            solver='lbfgs',\n",
    "            random_state=RANDOM_STATE\n",
    "        ))\n",
    "    ]),\n",
    "    \"Наивный Байес: модель Бернулли\": Pipeline([\n",
    "        ('vectorizer', hashing_vectorizer),\n",
    "        # Трансформер не нужен\n",
    "        ('classifier', BernoulliNB(alpha=1.0))\n",
    "    ]),\n",
    "    \"Наивный Байес: полиномиальная модель\": Pipeline([\n",
    "        ('vectorizer', hashing_vectorizer),\n",
    "        # Трансформер не нужен\n",
    "        ('classifier', MultinomialNB(alpha=1.0))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Установим лучшие параметры при ngram=(1, 1)\n",
    "ngram = (1, 1)\n",
    "set_best_params(pipelines_hashing, param_names, param_values_list, validation_scores[ngram])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names_hashing = ['vectorizer__n_features']*4\n",
    "param_values_list_hashing = [np.logspace(1, 5, 5, base=10, dtype=int)]*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_scores_hashing = get_validation_scores(pipelines_hashing, param_names_hashing, param_values_list_hashing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_validation_scores(\n",
    "    validation_scores=validation_scores_hashing,\n",
    "    score_keys=['train_score', 'test_score'],\n",
    "    score_labels=['Train', 'Test'],\n",
    "    highlight_key='test_score',\n",
    "    param_names=param_names_hashing,\n",
    "    param_values_list=param_values_list_hashing,\n",
    "    xscales=['log']*4,\n",
    "    title=f'Зависимость сбалансированной точности от гиперпараметров моделей [ngram={ngram}]'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
